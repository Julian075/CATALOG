import os
import torch
from torch.utils.data import Dataset, DataLoader
import torch.optim as optim
import argparse
from models import CATALOG_Base as base
from train.Base.Train_CATALOG_Base_out_domain import CATALOG_base
import numpy as np
import random
from PIL import Image
from transformers import BertModel, BertTokenizer
import clip
import json
import pandas as pd


if __name__ == "__main__":

    ruta_features_train = "features/Features_serengeti/standard_features/Features_CATALOG_train_16.pt"
    ruta_features_val = "features/Features_serengeti/standard_features/Features_CATALOG_val_16.pt"
    ruta_features_test1 = "features/Features_terra/standard_features/Features_CATALOG_cis_test_16.pt"
    ruta_features_test2 = "features/Features_terra/standard_features/Features_CATALOG_trans_test_16.pt"
    path_text_feat1 = "features/Features_serengeti/standard_features/Text_features_16.pt"
    path_text_feat2 = "features/Features_terra/standard_features/Text_features_16.pt"
    num_layers = 1
    dropout = 0.27822
    hidden_dim = 1045
    t = 0.1
    weight_Clip = 0.6

    model_params_path = 'models/CATALOG_Base.pth'


    def set_seed(seed):
        torch.manual_seed(seed)
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.
        np.random.seed(seed)
        random.seed(seed)
        torch.backends.cudnn.benchmark = False
        torch.backends.cudnn.deterministic = True




    def pru_ind(model_params_path,image_path,description_path,data):
        class_indices = {'badger': 0, 'bird': 1, 'bobcat': 2, 'car': 3, 'cat': 4, 'coyote': 5, 'deer': 6, 'dog': 7, \
                         'empty': 8, 'fox': 9, 'opossum': 10, 'rabbit': 11, 'raccoon': 12, 'rodent': 13, 'skunk': 14,
                         'squirrel': 15}

        device = "cuda" if torch.cuda.is_available() else "cpu"

        # Initialize your models, tokenizer, etc.
        tokenizer_Bert = BertTokenizer.from_pretrained('bert-base-uncased')
        model_Bert = BertModel.from_pretrained('bert-base-uncased')
        model_Bert.to(device)

        model_clip, preprocess_clip = clip.load('ViT-B/16', device)
        model_clip.to(device)

        text_features2 = torch.load(path_text_feat2)
        text_features2 = text_features2.to(device)

        projection_model = base.LLaVA_CLIP(hidden_dim=hidden_dim, num_layers=num_layers, dropout=dropout,
                                         pretrained=0, pretrained_path="")
        projection_model.load_state_dict(torch.load(model_params_path))
        projection_model = projection_model.to(device)
        projection_model.eval()

        root_dir = os.path.join(image_path)

        outputs={}
        for category in os.listdir(root_dir):
            category_path = os.path.join(root_dir, category)
            for img_name in os.listdir(category_path):
                img_path = os.path.join(category_path, img_name)
                # path where is located the images descriptions generated by LLaVA
                json_path = os.path.join(description_path, category, img_name[:-4] + '.json')

                #target_index = int(category)
                target_index = class_indices[category.lower()]

                images = preprocess_clip(Image.open(img_path).convert("RGB")).unsqueeze(0).to(device)

                with torch.no_grad():
                    image_features = model_clip.encode_image(images)
                    image_features /= image_features.norm(dim=-1, keepdim=True)

                # images = images.unsqueeze(0)[0]
                f = open(json_path)
                data = json.load(f)
                description = data['description']
                f.close()
                tokens = tokenizer_Bert.tokenize(description)
                tokens = ['[CLS]'] + tokens + ['[SEP]']
                attention_mask = [1 if token != '[PAD]' else 0 for token in tokens]
                token_ids = tokenizer_Bert.convert_tokens_to_ids(tokens)

                attention_mask = torch.tensor(attention_mask).unsqueeze(0).to(device)
                token_ids = torch.tensor(token_ids).unsqueeze(0).to(device)
                with torch.no_grad():
                    output_bert = model_Bert(token_ids, attention_mask=attention_mask)
                    description_embeddings = output_bert.pooler_output

                image_features = image_features.to(device)
                description_embeddings = description_embeddings.to(device)

                max_values, max_indices = projection_model.predict(description_embeddings,image_features, text_features2,
                                                                               weight_Clip, target_index, t)
                outputs[img_name[:-4]]={'class':target_index,'Prediction':int(max_indices.cpu()),'Value': float(max_values.cpu())}
        df=pd.DataFrame(outputs)
        df.to_csv(f'Predictions_{data}_test.csv')

    image_path='data/terra/img/trans_test'
    model_params_path='models/CATALOG_Base.pth'
    description_path='data/terra/descriptions/trans_test'
    pru_ind(model_params_path,image_path,description_path,'trans')

