
0
Input shape: torch.Size([48, 512])
Weight shape: torch.Size([512, 512])
Traceback (most recent call last):
  File "D:\Programass\PyCharm\PyCharm Community Edition 2021.3.2\plugins\python-ce\helpers\pydev\pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "D:\Programass\PyCharm\PyCharm Community Edition 2021.3.2\plugins\python-ce\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "D:/Udea/Maestria/Experimentos/Repositorios/CATALOG/main.py", line 269, in <module>
    model.train()
  File "D:\Udea\Maestria\Experimentos\Repositorios\CATALOG\train\Base\Train_CATALOG_Base_out_domain.py", line 93, in train
    loss, acc,_ = projection_model(description_embeddings, image_features, text_features, self.weight_Clip,target_index,self.t)
  File "C:\Users\Julia\AppData\Roaming\Python\Python310\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "D:\Udea\Maestria\Experimentos\Repositorios\CATALOG\models\CATALOG_Base_long.py", line 143, in forward
    logit_scale_CLIP = self.logit_scale_CLIP.exp()
  File "C:\Users\Julia\AppData\Roaming\Python\Python310\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "D:\Udea\Maestria\Experimentos\Repositorios\CATALOG\models\CATALOG_Base_long.py", line 66, in forward
  File "C:\Users\Julia\AppData\Roaming\Python\Python310\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\Julia\AppData\Roaming\Python\Python310\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
